{
    // 使用 IntelliSense 了解相关属性。 
    // 悬停以查看现有属性的描述。
    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "ft_qlora",
            "type": "python",
            "request": "launch",
            "program": "/workspace/finetune_trainer.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "envFile": "${workspaceFolder}/.vscode/.env",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
                "PYTHONPATH": "/workspace/:${PYTHONPATH}"
            },
            "args": [
                "--use_lora",
                "True",
                "--use_qlora",
                "True",
                "--lora_r",
                "8",
                "--unshared_r",
                "8",
                "--reduce_lora_A_x",
                "1",
                "--reduce_lora_B_x",
                "3",
                "--lora_alpha",
                "16",
                "--lora_dropout",
                "0.1",
                "--lora_modules",
                "all",
                "--enable_lora_vec",
                "True",
                "--enable_lora_rotation",
                "True",
                "--init2zero_via_vec",
                "False",
                "--model_name_or_path",
                "meta-llama/Llama-2-7b-hf",
                "--seed",
                "42",
                "--token",
                "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",
                "--output_dir",
                "./output/temp",
                "--overwrite_output_dir",
                "True",
                "--use_flash_attn",
                "False",
                "--gradient_checkpointing",
                "True",
                "--torch_dtype",
                "bfloat16",
                "--bf16",
                "True",
                "--tf32",
                "True",
                "--do_train",
                "True",
                "--train_file",
                "data/processed/super_ni/super_ni_data.jsonl",
                "--use_fast_tokenizer",
                "False",
                "--streaming",
                "False",
                "--overwrite_cache",
                "False",
                "--remove_unused_columns",
                "True",
                "--preprocessing_num_workers",
                "8",
                "--max_seq_length",
                "512",
                "--group_by_length",
                "False",
                "--optim",
                "paged_adamw_32bit",
                "--learning_rate",
                "2e-4",
                "--warmup_ratio",
                "0.03",
                "--lr_scheduler_type",
                "linear",
                "--per_device_train_batch_size",
                "16",
                "--gradient_accumulation_steps",
                "1",
                "--max_steps",
                "1",
                "--weight_decay",
                "0.0",
                "--max_grad_norm",
                "0.3",
                "--do_eval",
                "False",
                "--max_eval_samples",
                "1024",
                "--evaluation_strategy",
                "no",
                "--prediction_loss_only",
                "False",
                "--per_device_eval_batch_size",
                "16",
                "--eval_steps",
                "5",
                "--report_to",
                "tensorboard",
                "--logging_strategy",
                "steps",
                "--logging_steps",
                "1",
                "--save_strategy",
                "steps",
                "--save_steps",
                "7",
                "--save_total_limit",
                "2",
            ],
        },
        {
            "name": "eval_mmlu",
            "type": "python",
            "request": "launch",
            "program": "/workspace/eval/mmlu/run_eval.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "envFile": "${workspaceFolder}/.vscode/.env",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
                "PYTHONPATH": "/workspace/:${PYTHONPATH}"
            },
            "args": [
                "--ntrain",
                "0",
                "--data_dir",
                "data/eval/mmlu",
                "--save_dir",
                "output/temp_mmlu_results",
                "--model_name_or_path",
                "meta-llama/Llama-2-7b-hf",
                "--tokenizer_name_or_path",
                "meta-llama/Llama-2-7b-hf",
                "--eval_batch_size",
                "16",
                "--use_slow_tokenizer",
                "--load_in_8bit",
                "--use_chat_format",
                "--chat_formatting_function",
                "eval.templates.create_prompt_with_tulu_chat_format",
            ],
        },
        {
            "name": "merge_lora",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/open_instruct/merge_lora.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "envFile": "${workspaceFolder}/.vscode/.env",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
                "PYTHONPATH": "/workspace/:${PYTHONPATH}"
            },
            "args": [
                "--base_model_name_or_path",
                "meta-llama/Llama-2-7b-hf",
                "--lora_model_name_or_path",
                "./output/superni_20231126-224517_GPU_3_r_64_x_1_lr_0.0001_sd_1",
                "--output_dir",
                "./output/superni_20231126-224517_GPU_3_r_64_x_1_lr_0.0001_sd_1/lora_merged/",
                "--qlora",
                "--save_tokenizer",
            ],
        },
        {
            "name": "reformat_datasets",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/open_instruct/reformat_datasets.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "envFile": "${workspaceFolder}/.vscode/.env",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
                "PYTHONPATH": "/workspace/:${PYTHONPATH}"
            },
            "args": [
                "--raw_data_dir",
                "data/raw_train/",
                "--output_dir",
                "data/processed/"
            ],
        },
        {
            "name": "Python: Current File",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": true,
            "envFile": "${workspaceFolder}/.vscode/.env",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
                "PYTHONPATH": "/workspace/:${PYTHONPATH}"
            },
            "args": [],
        }
    ]
}
// configuration 配置文件属性
// 对与每一种（语言）调试器都会有自己特有的配置信息，可以 利用 IntelliSense suggestions 去查询存在的配置项的信息，一般都会有备注说明。
// • version：版本号，不用修改
// • configurations：数组类型，用来配置 每一项调试任务的具体配置信息
// • type：调试环境的具体类型 node、java、cppdbg 等等
// • name：调试任务的名称，用与在下拉列表中展示
// • program：启动文件的路径，对于该路径中的变量，下面在介绍
// • request：调试模式，一共有两种模式
//      launch：和应用一起启动
//      attach：应用已经启动了，但是又想在不重新启动的情况下调试该应用，就可以把调试器附加到应用上
// • runtimeExecutable：应用程序执行的时候的执行期，默认是 node，应该为决定路径或者添加到 PATH 路径上的
// • console：启动调试终端的位置，一般都 3 个值，如果你的打印信息出现在终端上，不能很好的查看对应变量值可以调整这个值
//      internalConsole：VS Code 的调试控制台
//      integratedTerminal：VS Code 的集成终端
//      externalTerminal：VS Code 外部的集成终端
// • env：对象，程序启动是传递的环境变量
// • args：程序启动是传递的参数
// • cwd：程序启动是的跟目录配置
// • window：为 window 平台单独设置配置项
// • linux：为 linux 平台单独设置配置项
// • osx：为 Mac OS 平台单独设置配置项